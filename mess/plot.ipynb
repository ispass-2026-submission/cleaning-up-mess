{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92982eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "bytes_per_RW = 64\n",
    "tCK_ps = 416  # DDR5 clock period in picoseconds\n",
    "mem_clk_freq = 1 / (tCK_ps * 1e-12)  # Hz\n",
    "\n",
    "max_achieved_bandwidth = 0\n",
    "\n",
    "num_channels = 16\n",
    "\n",
    "result_dir = f'ddr5_4800an_{num_channels}ch'\n",
    "\n",
    "input_dirs = [\n",
    "    (\"100% reads\", f\"./{result_dir}/read\"),\n",
    "    (\"50% reads\", f\"./{result_dir}/read_write\"),\n",
    "    (\"60% reads\", f\"./{result_dir}/custom_60\"),\n",
    "    (\"70% reads\", f\"./{result_dir}/custom_70\"),\n",
    "    (\"80% reads\", f\"./{result_dir}/custom_80\"),\n",
    "    (\"90% reads\", f\"./{result_dir}/custom_90\")\n",
    "]\n",
    "\n",
    "# colorbar labels\n",
    "label_to_reads = {\n",
    "    \"100% reads\": 100,\n",
    "    \"95% reads\": 95,\n",
    "    \"90% reads\": 90,\n",
    "    \"85% reads\": 85,\n",
    "    \"80% reads\": 80,\n",
    "    \"75% reads\": 75,\n",
    "    \"70% reads\": 70,\n",
    "    \"65% reads\": 65,\n",
    "    \"60% reads\": 60,\n",
    "    \"55% reads\": 55,\n",
    "    \"50% reads\": 50,\n",
    "}\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for label, output_dir in input_dirs:\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(output_dir):\n",
    "        if filename.startswith('output_') and filename.endswith('.txt'):\n",
    "            match = re.match(r'output_(\\d+)\\.txt', filename)\n",
    "            if match:\n",
    "                nop_count = int(match.group(1))\n",
    "                filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "                memory_cycles = None\n",
    "                avg_latency_ns = None\n",
    "\n",
    "                total_number_of_writes = None\n",
    "                total_number_of_reads = None\n",
    "\n",
    "                with open(filepath, 'r') as file:\n",
    "                    for line in file:\n",
    "                        if 'memory_system_cycles' in line:\n",
    "                            cycle_match = re.search(r'memory_system_cycles:\\s*(\\d+)', line)\n",
    "                            if cycle_match:\n",
    "                                memory_cycles = int(cycle_match.group(1))\n",
    "                        if 'total_num_write_requests' in line:\n",
    "                            write_match = re.search(r'total_num_write_requests:\\s*(\\d+)', line)\n",
    "                            if write_match:\n",
    "                                total_number_of_writes = float(write_match.group(1))\n",
    "                        if 'total_num_read_requests' in line:\n",
    "                            read_match = re.search(r'total_num_read_requests:\\s*(\\d+)', line)\n",
    "                            if read_match:\n",
    "                                total_number_of_reads = float(read_match.group(1)) \n",
    "                        if 'avg_read_latency_0' in line:\n",
    "                            lat_match = re.search(r'avg_read_latency_0:\\s*([\\d.]+)', line)\n",
    "                            if lat_match:\n",
    "                                avg_latency_ns = float(lat_match.group(1))*tCK_ps/1000\n",
    "                        if 'avg_queue_time_stream0' in line:\n",
    "                            lat_match = re.search(r'avg_queue_time_stream0:\\s*([\\d.]+)', line)\n",
    "                            if lat_match:\n",
    "                                avg_stream_queue = float(lat_match.group(1))/(1000/tCK_ps)\n",
    "                        if 'avg_random_read_latency_0' in line:\n",
    "                            lat_match = re.search(r'avg_random_read_latency_0:\\s*([\\d.]+)', line)\n",
    "                            if lat_match:\n",
    "                                avg_random_read_latency = float(lat_match.group(1))/(1000/tCK_ps)\n",
    "                        if 'average_strided_read_latency_0' in line:\n",
    "                            lat_match = re.search(r'average_strided_read_latency_0:\\s*([\\d.]+)', line)\n",
    "                            if lat_match:\n",
    "                                avg_strided_latency_ns = float(lat_match.group(1))/(1000/tCK_ps)\n",
    "                        if 'total_number_of_retried_requests' in line:\n",
    "                            lat_match = re.search(r'total_number_of_retried_requests:\\s*([\\d.]+)', line)\n",
    "                            if lat_match:\n",
    "                                total_number_of_retried_requests = int(lat_match.group(1))\n",
    "\n",
    "                if memory_cycles is not None and avg_latency_ns is not None and total_number_of_writes is not None and total_number_of_reads is not None:\n",
    "                    time_sec = memory_cycles / mem_clk_freq\n",
    "                    num_RW = total_number_of_reads + total_number_of_writes\n",
    "                    bandwidth_GBps = ((bytes_per_RW * num_RW) / time_sec) / 1e9\n",
    "\n",
    "                    numTotalBytes = num_RW * bytes_per_RW\n",
    "                    bytes_per_cycle = numTotalBytes / memory_cycles\n",
    "                    cycles_per_cb = 64 / bytes_per_cycle\n",
    "                    expected_cycles_per_cb = 8 # tCCDS = 8\n",
    "\n",
    "                    expected_bandwidth = (1e9 / (tCK_ps/1000)) / 8 * 64 / 1e9\n",
    "\n",
    "                    if bandwidth_GBps > max_achieved_bandwidth: \n",
    "                        max_achieved_bandwidth = bandwidth_GBps\n",
    "\n",
    "                    data.append((bandwidth_GBps, avg_latency_ns, nop_count, avg_stream_queue, avg_strided_latency_ns, avg_random_read_latency, total_number_of_retried_requests))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Bandwidth (GB/s)', 'Avg Read Latency (ns)', 'NOP Count', 'Avg Stream Queue (ns)', 'Avg Strided Latency (ns)', 'Avg Random Read Latency (ns)', 'Total Number of Retried Requests'])\n",
    "    df = df.sort_values('NOP Count')\n",
    "    df['Label'] = label\n",
    "    all_dfs.append(df)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "custom_colors = [\n",
    "    (0.0, \"#0000AA\"),  \n",
    "    (1.0, \"#AA0000\"),  \n",
    "]\n",
    "\n",
    "trunc_cmap = LinearSegmentedColormap.from_list(\"custom_blue_red\", custom_colors)\n",
    "\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=50, vmax=100)\n",
    "sm = plt.cm.ScalarMappable(cmap=trunc_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "colors = [trunc_cmap(norm(label_to_reads[df['Label'].iloc[0]])) for df in all_dfs]\n",
    "\n",
    "for i, df in enumerate(all_dfs):\n",
    "    plt.plot(df['Bandwidth (GB/s)'], df['Avg Random Read Latency (ns)'],\n",
    "         linestyle='-', label='_nolegend_', color=colors[i], linewidth=2)\n",
    "\n",
    "cbar = plt.colorbar(sm, ax=plt.gca(), pad=0.02)\n",
    "cbar.set_label('% Reads', fontsize=18)\n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "\n",
    "# max_bandwidth = (1000000000/((8 * 0.416))) * 64 * num_channels /1e9 # from clock period\n",
    "max_bandwidth = (4800 * 32/8) / 1000 * num_channels # from data rate\n",
    "\n",
    "plt.axvline(x=max_bandwidth, color='orange', linestyle='--', linewidth=2, label='Max. Theoretical BW (No Refresh)')\n",
    "plt.text(max_bandwidth, plt.ylim()[1]*1.05, f'{max_bandwidth:.1f}', ha='center', va='top', fontsize=15, color='orange')\n",
    "\n",
    "nanoseconds_gone_to_refresh = 329.472\n",
    "gone_per_refi = (nanoseconds_gone_to_refresh / 3900)\n",
    "bandwidth_after_refresh = max_bandwidth * (1 - gone_per_refi)\n",
    "\n",
    "gone_per_refi_jedec_small = (793 * 0.416)/3900\n",
    "bandwidth_after_refresh_jedec_small = max_bandwidth * (1 - gone_per_refi_jedec_small)\n",
    "\n",
    "plt.axvline(x=bandwidth_after_refresh_jedec_small, color='green', linestyle='--', linewidth=2, label='Max. Achievable BW (With All-Bank Refresh)')\n",
    "plt.text(bandwidth_after_refresh_jedec_small, plt.ylim()[1]*1.05, f'{bandwidth_after_refresh_jedec_small:.1f}', ha='center', va='top', fontsize=15, color='green')\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', direction='in', length=6, width=2)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "plt.xlabel('Used memory bandwidth (GB/s)', fontsize=20, labelpad=10)\n",
    "plt.ylabel('Memory access latency (ns)', fontsize=20, labelpad=10)\n",
    "plt.grid(True, linestyle='--', linewidth=1.3, alpha=0.7)\n",
    "\n",
    "legend = plt.legend(fontsize=18, frameon=True, edgecolor='black', facecolor='white', loc='upper center', bbox_to_anchor=(0.5, 1.35))\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "ax = plt.gca() \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'latency_bandwidth_{num_channels}ch.png', dpi=300)\n",
    "plt.savefig(f'latency_bandwidth_{num_channels}ch.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"max bandwidth is {max_achieved_bandwidth}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
